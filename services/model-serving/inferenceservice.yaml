apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: model-serving
spec:
  predictor:
    custom:
      container:
        image: model-serving:latest
        name: model-serving
        ports:
          - containerPort: 8080
